{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import PIL\n",
                "import tensorflow as tf\n",
                "\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.models import Sequential"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#images are in ./dataset/khalil and ./dataset/others\n",
                "# labels are the folder names\n",
                "# load the data\n",
                "\n",
                "import os\n",
                "import numpy as np\n",
                "\n",
                "data_path = './dataset'\n",
                "folders = os.listdir(data_path)\n",
                "labels = []\n",
                "images = []\n",
                "\n",
                "# each image has a label. labels are the folder names.\n",
                "for folder in folders:\n",
                "    folder_path = os.path.join(data_path, folder)\n",
                "    for image in os.listdir(folder_path):\n",
                "        image_path = os.path.join(folder_path, image)\n",
                "        images.append(image_path)\n",
                "        labels.append(folder)\n",
                "\n",
                "# convert to numpy arrays\n",
                "images = np.array(images)\n",
                "labels = np.array(labels)\n",
                "print(images)\n",
                "print(labels)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Image Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## HaaR Cascade Face Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                " #detect faces in the image and extract the face\n",
                "\n",
                "import cv2\n",
                "haar_file = 'haarcascade_frontalface_default.xml'\n",
                "face_cascade = cv2.CascadeClassifier(haar_file)\n",
                "\n",
                "def face_extractor(img):\n",
                "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
                "    if faces is ():\n",
                "        return None\n",
                "    for (x, y, w, h) in faces:\n",
                "        cropped_face = img[y:y+h, x:x+w]\n",
                "    return cropped_face\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# function to extract faces from an image\n",
                "def faces_extractor(img):\n",
                "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
                "    if faces is ():\n",
                "        return None\n",
                "    faces_list = []\n",
                "    for (x, y, w, h) in faces:\n",
                "        cropped_face = img[y:y+h, x:x+w]\n",
                "        faces_list.append(cropped_face)\n",
                "    return faces_list\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "testing the face detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "\n",
                "for image in images:\n",
                "    img = mpimg.imread(image)\n",
                "\n",
                "    face = face_extractor(img)\n",
                "    if face is not None:\n",
                "        plt.imshow(face)\n",
                "        plt.show()\n",
                "    else:\n",
                "        print('Face not found')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save the faces in \"processed\" folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save the faces in \"processed\" folder. The folder will be created if it doesn't exist.\n",
                "# the faces are saved with the name of the folder they belong to (label) and a number.\n",
                "processed_path = './processed'\n",
                "if not os.path.exists(processed_path):\n",
                "    os.mkdir(processed_path)\n",
                "#clean the folder\n",
                "for folder in os.listdir(processed_path):\n",
                "    folder_path = os.path.join(processed_path, folder)\n",
                "    for file in os.listdir(folder_path):\n",
                "        file_path = os.path.join(folder_path, file)\n",
                "        os.remove(file_path)\n",
                "    os.rmdir(folder_path)\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "\n",
                "for i, image in enumerate(images):\n",
                "    img = cv2.imread(image)\n",
                "    face = face_extractor(img)\n",
                "    if face is not None:\n",
                "        face = cv2.resize(face, (256, 256))\n",
                "    \n",
                "        save_path = os.path.join(processed_path, labels[i])\n",
                "        if not os.path.exists(save_path):\n",
                "            os.mkdir(save_path)\n",
                "        file_name_path = os.path.join(save_path, labels[i] + str(i) + '.jpg')\n",
                "        cv2.imwrite(file_name_path, face)\n",
                "        cv2.waitKey(0)\n",
                "    else:\n",
                "        print('Face not found')\n",
                "        pass\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CNN Model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load data and divide into train and test sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = './processed/'\n",
                "batch_size = 32\n",
                "image_size=(256,256)\n",
                "training_set = tf.keras.utils.image_dataset_from_directory(\n",
                "    data,\n",
                "    validation_split=0.2,\n",
                "    subset=\"training\",\n",
                "    image_size=image_size,\n",
                "    seed=55,\n",
                "    batch_size=batch_size,\n",
                ")\n",
                "\n",
                "testing_set = tf.keras.utils.image_dataset_from_directory(\n",
                "    data,\n",
                "    validation_split=0.2,\n",
                "    subset=\"validation\",\n",
                "    seed=55,\n",
                "    image_size=image_size,\n",
                "    batch_size=batch_size,)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_names = training_set.class_names\n",
                "print(class_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nb_labels = [0, 0, 0]\n",
                "for image_batch, labels_batch in training_set:\n",
                "    nb_labels[0] = nb_labels[0]+labels_batch.numpy().tolist().count(0)\n",
                "    nb_labels[1] = nb_labels[1]+labels_batch.numpy().tolist().count(1)\n",
                "    nb_labels[2] = nb_labels[2]+labels_batch.numpy().tolist().count(2)\n",
                "\n",
                "print(nb_labels)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizing the data\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(10, 10))\n",
                "for images, labels in training_set.take(1):\n",
                "    for i in range(9):\n",
                "        ax = plt.subplot(3, 3, i + 1)\n",
                "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
                "        plt.title(class_names[labels[i]])\n",
                "        plt.axis(\"off\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Data augmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_augmentation = tf.keras.Sequential([\n",
                "    layers.RandomFlip(\"horizontal_and_vertical\", input_shape=(256, 256, 3)),\n",
                "    layers.RandomRotation(0.2),\n",
                "    layers.RandomZoom(0.2),\n",
                "    layers.RandomContrast(0.2),]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# generating train and test data\n",
                "number_of_augments=3\n",
                "_aug_ds_new = training_set.unbatch()\n",
                "aug_ds_new = training_set.map(lambda x, y: (data_augmentation(x), y))\n",
                "\n",
                "aug_ds_new = aug_ds_new.unbatch()\n",
                "aug_ds_new = aug_ds_new.concatenate(_aug_ds_new)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(number_of_augments):\n",
                "    aug_ds_=training_set.map(lambda x, y: (data_augmentation(x), y))\n",
                "    # print(i)\n",
                "    # for images, labels in aug_ds_:\n",
                "    #     print(images.shape)\n",
                "    \n",
                "    # print('-----------------')\n",
                "    aug_ds_new=aug_ds_new.concatenate(aug_ds_.unbatch())\n",
                "    # for images, labels in aug_ds_new:\n",
                "    #     print(images.shape)\n",
                "    # print('-----------------')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "aug_ds_new=aug_ds_new.batch(32)\n",
                "train_data_augmented = aug_ds_new"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for image_batch, labels_batch in aug_ds_new:\n",
                "    print(image_batch.shape)\n",
                "    print(labels_batch.numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nb_labels = [0,0,0]\n",
                "for image_batch, labels_batch in aug_ds_new:\n",
                "    nb_labels[0]=nb_labels[0]+labels_batch.numpy().tolist().count(0)\n",
                "    nb_labels[1]=nb_labels[1]+labels_batch.numpy().tolist().count(1)\n",
                "    nb_labels[2]=nb_labels[2]+labels_batch.numpy().tolist().count(2)\n",
                "\n",
                "print(nb_labels)\n",
                "    \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A basic Keras model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_classes = len(class_names)\n",
                "\n",
                "model = Sequential([\n",
                "  layers.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
                "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
                "  layers.MaxPooling2D(),\n",
                "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
                "  layers.MaxPooling2D(),\n",
                "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
                "  layers.MaxPooling2D(),\n",
                "  layers.Flatten(),\n",
                "  layers.Dense(128, activation='relu'),\n",
                "  layers.Dense(num_classes)\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compile the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(optimizer='adam',\n",
                "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
                "              metrics=['accuracy'])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Train the model (Train the model for 10 epochs with the Keras Model.fit method):\n",
                "\n",
                "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss',  patience=3)\n",
                "# This callback will stop the training when there is no improvement in the loss for 2 consecutive epochs.\n",
                "\n",
                "#history = model.fit(\n",
                "  #training_set,\n",
                "  #validation_data=testing_set,\n",
                "  #epochs=20, \n",
                "  #callbacks=[callback],)\n",
                "#epochs=len(history.history['loss'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Train the model "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 5\n",
                "history = model.fit(\n",
                "    train_data_augmented,\n",
                "    validation_data=testing_set,\n",
                "    epochs=epochs\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Visualize training results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc = history.history['accuracy']\n",
                "val_acc = history.history['val_accuracy']\n",
                "\n",
                "loss = history.history['loss']\n",
                "val_loss = history.history['val_loss']\n",
                "\n",
                "epochs_range = range(epochs)\n",
                "\n",
                "plt.figure(figsize=(8, 8))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
                "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
                "plt.legend(loc='lower right')\n",
                "plt.title('Training and Validation Accuracy')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(epochs_range, loss, label='Training Loss')\n",
                "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
                "plt.legend(loc='upper right')\n",
                "plt.title('Training and Validation Loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Predict on new data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "im_path = './test_images/malek10.jpg'\n",
                "\n",
                "img = tf.keras.utils.load_img(\n",
                "    im_path, target_size=(256, 256)\n",
                ")\n",
                "img_array = tf.keras.utils.img_to_array(img)\n",
                "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
                "\n",
                "predictions = model.predict(img_array)\n",
                "score = tf.nn.softmax(predictions[0])\n",
                "\n",
                "print(\n",
                "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
                "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save the model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model.save('model_khalil_malek_best.h5')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "load the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "loaded_model = tf.keras.models.load_model('model_khalil_malek_best.h5')\n",
                "class_names = ['khalil', 'malek','others']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Show Prediction and Accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "image = cv2.imread('./test_images/many.jpeg')\n",
                "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "cv2_im = image.copy()\n",
                "# plt.imshow(image)\n",
                "faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
                "if faces is ():\n",
                "    print('No faces found')\n",
                "    plt.text(0, 0, 'No faces found', fontsize=20)\n",
                "for (x, y, w, h) in faces:\n",
                "    \n",
                "    cv2.rectangle(cv2_im, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
                "    # use plt to draw the rectangle\n",
                "    # plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=2))\n",
                "    # cv2.rectangle(cv2_im, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
                "    #predict and show the name\n",
                "    roi = image[y:y+h, x:x+w]\n",
                "    roi = cv2.resize(roi, (256, 256))\n",
                "    roi_array = tf.keras.utils.img_to_array(roi)\n",
                "    roi_array = np.expand_dims(roi_array, 0)\n",
                "    prediction = model.predict(roi_array)\n",
                "    score = tf.nn.softmax(prediction[0])\n",
                "    print(prediction)\n",
                "    print(class_names[np.argmax(prediction)])\n",
                "    # plt.text(x, y, class_names[np.argmax(prediction)], color='white', fontsize=20, backgroundcolor='red')\n",
                "    cv2.putText(cv2_im, class_names[np.argmax(prediction)], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
                "    # show accuracy\n",
                "    # plt.text(x, y+h, str(round(np.max(score)*100))+'%',\n",
                "            #  color='white', fontsize=8, backgroundcolor='green')\n",
                "    cv2.putText(cv2_im, str(round(np.max(score)*100))+'%', (x, y+h), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
                "\n",
                "# plt.axis('off')\n",
                "# plt.subplots_adjust(0, 0, 1, 1, 0, 0)\n",
                "\n",
                "cv2_im = cv2.cvtColor(cv2_im, cv2.COLOR_BGR2RGB)\n",
                "cv2.imwrite('./result/result.jpg', cv2_im)\n",
                "# show the image using cv2\n",
                "cv2.imshow('result', cv2_im)\n",
                "cv2.waitKey(0)\n",
                "cv2.destroyAllWindows()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.2 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
