{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images are in ./dataset/khalil and ./dataset/others\n",
    "# labels are the folder names\n",
    "# load the data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_path = './dataset'\n",
    "folders = os.listdir(data_path)\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# each image has a label. labels are the folder names.\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_path, folder)\n",
    "    for image in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        images.append(image_path)\n",
    "        labels.append(folder)\n",
    "\n",
    "# convert to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "print(images)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #detect faces in the image and extract the face\n",
    "\n",
    "import cv2\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "def face_extractor(img):\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract faces from an image\n",
    "def faces_extractor(img):\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    faces_list = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        faces_list.append(cropped_face)\n",
    "    return faces_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)\n",
    "\n",
    "    face = face_extractor(img)\n",
    "    if face is not None:\n",
    "        plt.imshow(face)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Face not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the faces in \"processed\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the faces in \"processed\" folder. The folder will be created if it doesn't exist.\n",
    "# the faces are saved with the name of the folder they belong to (label) and a number.\n",
    "processed_path = './processed'\n",
    "if not os.path.exists(processed_path):\n",
    "    os.mkdir(processed_path)\n",
    "#clean the folder\n",
    "for folder in os.listdir(processed_path):\n",
    "    folder_path = os.path.join(processed_path, folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        os.remove(file_path)\n",
    "    os.rmdir(folder_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    img = cv2.imread(image)\n",
    "    face = face_extractor(img)\n",
    "    if face is not None:\n",
    "        face = cv2.resize(face, (256, 256))\n",
    "    \n",
    "        save_path = os.path.join(processed_path, labels[i])\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "        file_name_path = os.path.join(save_path, labels[i] + str(i) + '.jpg')\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        print('Face not found')\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and divide into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './processed/'\n",
    "batch_size = 32\n",
    "image_size=(256,256)\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data,\n",
    "    validation_split=0.5,\n",
    "    subset=\"training\",\n",
    "    image_size=image_size,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "testing_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    data,\n",
    "    validation_split=0.5,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = training_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in training_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", input_shape=(256, 256, 3)),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and test data\n",
    "number_of_augments=3\n",
    "_aug_ds_new = training_set.unbatch()\n",
    "aug_ds_new = training_set.shuffle(100).map(lambda x, y: (data_augmentation(x), y))\n",
    "\n",
    "aug_ds_new = aug_ds_new.unbatch()\n",
    "aug_ds_new = aug_ds_new.concatenate(_aug_ds_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(number_of_augments):\n",
    "    aug_ds_=training_set.shuffle(100).map(lambda x, y: (data_augmentation(x), y))\n",
    "    print(i)\n",
    "    for images, labels in aug_ds_:\n",
    "        print(images.shape)\n",
    "    \n",
    "    print('-----------------')\n",
    "    aug_ds_new=aug_ds_new.concatenate(aug_ds_.unbatch())\n",
    "    for images, labels in aug_ds_new:\n",
    "        print(images.shape)\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ds_new=aug_ds_new.batch(32)\n",
    "train_data_augmented = aug_ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in aug_ds_new:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model (Train the model for 10 epochs with the Keras Model.fit method):\n",
    "\n",
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss',  patience=3)\n",
    "# This callback will stop the training when there is no improvement in the loss for 2 consecutive epochs.\n",
    "\n",
    "#history = model.fit(\n",
    "  #training_set,\n",
    "  #validation_data=testing_set,\n",
    "  #epochs=20, \n",
    "  #callbacks=[callback],)\n",
    "#epochs=len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_data_augmented,\n",
    "    validation_data=testing_set,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = 'malek9.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    im_path, target_size=(256, 256)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff39798ba2f49d9c8c85df32f9bbb83f5fb04a27d2e6570577e90ab0f793dad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
