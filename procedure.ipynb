{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faces_extractor(img):\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    faces_list = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        faces_list.append(cropped_face)\n",
    "    return faces_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in a image and put a rectangle around each face using faces_extractor\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# load model\n",
    "model = tf.keras.models.load_model('model9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['khalil','others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "image = cv2.imread('many.jpeg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cv2_im = image.copy()\n",
    "# plt.imshow(image)\n",
    "faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
    "if faces is ():\n",
    "    print('No faces found')\n",
    "    plt.text(0, 0, 'No faces found', fontsize=20)\n",
    "for (x, y, w, h) in faces:\n",
    "    \n",
    "    cv2.rectangle(cv2_im, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    # use plt to draw the rectangle\n",
    "    # plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=2))\n",
    "    # cv2.rectangle(cv2_im, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    #predict and show the name\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    roi = cv2.resize(roi, (256, 256))\n",
    "    roi_array = tf.keras.utils.img_to_array(roi)\n",
    "    roi_array = np.expand_dims(roi_array, 0)\n",
    "    prediction = model.predict(roi_array)\n",
    "    score = tf.nn.softmax(prediction[0])\n",
    "    print(prediction)\n",
    "    print(class_names[np.argmax(prediction)])\n",
    "    # plt.text(x, y, class_names[np.argmax(prediction)], color='white', fontsize=20, backgroundcolor='red')\n",
    "    cv2.putText(cv2_im, class_names[np.argmax(prediction)], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "    # show accuracy\n",
    "    # plt.text(x, y+h, str(round(np.max(score)*100))+'%',\n",
    "            #  color='white', fontsize=8, backgroundcolor='green')\n",
    "    cv2.putText(cv2_im, str(round(np.max(score)*100))+'%', (x, y+h), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "# plt.axis('off')\n",
    "# plt.subplots_adjust(0, 0, 1, 1, 0, 0)\n",
    "\n",
    "cv2_im = cv2.cvtColor(cv2_im, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('result.jpg', cv2_im)\n",
    "# show the image using cv2\n",
    "cv2.imshow('result', cv2_im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# plt.savefig('plot.jpg', bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "#resize the plot to image size\n",
    "\n",
    "# plt.show()\n",
    "# save the plot\n",
    "# g=cv2.imread('result.jpg')\n",
    "# g=cv2.cvtColor(g,cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(g)\n",
    "# cv2.imshow('img', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('model9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"khalil\",\"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "im_path = 'khalil9.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    im_path, target_size=(256, 256)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('many.jpeg')\n",
    "face, face_img = face_detector(image)\n",
    "while True:\n",
    "    try:\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face_img)\n",
    "        if result[1] < 500:\n",
    "            confidence = int(100 * (1 - (result[1])/400))\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "        cv2.putText(face, display_string, (100, 120),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (250, 120, 255), 2)\n",
    "        if confidence > 75:\n",
    "            cv2.putText(face, \"Hey, I know you\", (250, 450),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow('Face Recognition', face)\n",
    "        else:\n",
    "            cv2.putText(face, \"I don't know, who are you?\", (250, 450),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow('Face Recognition', face)\n",
    "    except:\n",
    "        cv2.putText(face, \"No Face Found\", (220, 120),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(face, \"Looking for Face...\", (210, 450),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 0), 2)\n",
    "        cv2.imshow('Face Recognition', face)\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13:  # 13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff39798ba2f49d9c8c85df32f9bbb83f5fb04a27d2e6570577e90ab0f793dad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
